{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a1c3d949",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "import nltk\n",
    "import re\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "\n",
    "import gensim\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "\n",
    "from transformers import BertTokenizer, BertModel\n",
    "\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, roc_curve, auc\n",
    "\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "afb7b4a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the CSV file\n",
    "df = pd.read_csv(\"data/Fake.csv\")\n",
    "\n",
    "# Get the number of rows in the CSV file\n",
    "n_rows = len(df)\n",
    "\n",
    "# Sample 20% of the rows randomly\n",
    "sample_size = int(n_rows * 0.2)\n",
    "random_indices = np.random.choice(n_rows, sample_size, replace=False)\n",
    "\n",
    "# Create a new CSV file with the sampled rows\n",
    "df_sample = df.iloc[random_indices]\n",
    "df_sample.to_csv(\"data/fake_test_20.csv\", index=False)\n",
    "\n",
    "# Save the rest of the rows into a new CSV file\n",
    "df_rest = df.loc[~df.index.isin(random_indices)]\n",
    "df_rest.to_csv(\"data/fake_train_80.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2fb6c8a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the CSV file\n",
    "df = pd.read_csv(\"data/Real.csv\")\n",
    "\n",
    "# Get the number of rows in the CSV file\n",
    "n_rows = len(df)\n",
    "\n",
    "# Sample 20% of the rows randomly\n",
    "sample_size = int(n_rows * 0.2)\n",
    "random_indices = np.random.choice(n_rows, sample_size, replace=False)\n",
    "\n",
    "# Create a new CSV file with the sampled rows\n",
    "df_sample = df.iloc[random_indices]\n",
    "df_sample.to_csv(\"data/real_test_20.csv\", index=False)\n",
    "\n",
    "# Save the rest of the rows into a new CSV file\n",
    "df_rest = df.loc[~df.index.isin(random_indices)]\n",
    "df_rest.to_csv(\"data/real_train_80.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b19a92e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>subject</th>\n",
       "      <th>date</th>\n",
       "      <th>isReal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>As U.S. budget fight looms, Republicans flip t...</td>\n",
       "      <td>WASHINGTON (Reuters) - The head of a conservat...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>December 31, 2017</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>U.S. military to accept transgender recruits o...</td>\n",
       "      <td>WASHINGTON (Reuters) - Transgender people will...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>December 29, 2017</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FBI Russia probe helped by Australian diplomat...</td>\n",
       "      <td>WASHINGTON (Reuters) - Trump campaign adviser ...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>December 30, 2017</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>White House, Congress prepare for talks on spe...</td>\n",
       "      <td>WEST PALM BEACH, Fla./WASHINGTON (Reuters) - T...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>December 29, 2017</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Trump says Russia probe will be fair, but time...</td>\n",
       "      <td>WEST PALM BEACH, Fla (Reuters) - President Don...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>December 29, 2017</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  As U.S. budget fight looms, Republicans flip t...   \n",
       "1  U.S. military to accept transgender recruits o...   \n",
       "2  FBI Russia probe helped by Australian diplomat...   \n",
       "3  White House, Congress prepare for talks on spe...   \n",
       "4  Trump says Russia probe will be fair, but time...   \n",
       "\n",
       "                                                text       subject  \\\n",
       "0  WASHINGTON (Reuters) - The head of a conservat...  politicsNews   \n",
       "1  WASHINGTON (Reuters) - Transgender people will...  politicsNews   \n",
       "2  WASHINGTON (Reuters) - Trump campaign adviser ...  politicsNews   \n",
       "3  WEST PALM BEACH, Fla./WASHINGTON (Reuters) - T...  politicsNews   \n",
       "4  WEST PALM BEACH, Fla (Reuters) - President Don...  politicsNews   \n",
       "\n",
       "                 date  isReal  \n",
       "0  December 31, 2017        1  \n",
       "1  December 29, 2017        1  \n",
       "2  December 30, 2017        1  \n",
       "3  December 29, 2017        1  \n",
       "4  December 29, 2017        1  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the data\n",
    "df_real = pd.read_csv(\"data/real_train_80.csv\") \n",
    "df_fake = pd.read_csv(\"data/fake_train_80.csv\")\n",
    "\n",
    "# Add labels to the datasets\n",
    "df_fake['isReal'] = 0  # add label\n",
    "df_real['isReal'] = 1  # add label\n",
    "\n",
    "# Concatenate real and fake news\n",
    "df = pd.concat([df_real, df_fake]).reset_index(drop = True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "051f7a81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "isReal\n",
      "0    18785\n",
      "1    17134\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Dataset is class-balanced\n"
     ]
    }
   ],
   "source": [
    "# Check if the dataset is class-unbalanced or not\n",
    "print( df['isReal'].value_counts() )\n",
    "print()\n",
    "if 0.9 < (df['isReal'].value_counts()[0] / df['isReal'].value_counts()[1]) < 1.1:\n",
    "  print('Dataset is class-balanced')\n",
    "else:\n",
    "  print('Dataset is class-unbalenced')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "953749a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\frank\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Combine title and text together\n",
    "df['combine'] = df['title'] + ' ' + df['text']\n",
    "# Shuffle the dataFrame\n",
    "df = df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# Download stopwords\n",
    "nltk.download(\"stopwords\")\n",
    "\n",
    "# Endlish stopwords\n",
    "stop_words = stopwords.words('english')\n",
    "stop_words[:10]\n",
    "\n",
    "# Remove stopwords and remove words with 2 or less characters\n",
    "def preprocess(text):\n",
    "    result = []\n",
    "    for token in gensim.utils.simple_preprocess(text):\n",
    "        if token not in gensim.parsing.preprocessing.STOPWORDS and len(token) > 3 and token not in stop_words:\n",
    "            result.append(token)\n",
    "            \n",
    "    return result\n",
    "\n",
    "# Apply the function to the dataframe\n",
    "df['clean'] = df['combine'].apply(preprocess)\n",
    "\n",
    "# Join the words into a string\n",
    "df['clean_joined'] = df['clean'].apply(lambda x: \" \".join(x))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fc05c630",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "from torchinfo import summary\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "import nltk\n",
    "import re\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "\n",
    "import gensim\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "\n",
    "from transformers import BertTokenizer, BertModel, AutoTokenizer, AutoModelForSequenceClassification\n",
    "from tqdm import tqdm  # For progress bar\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, roc_curve, auc, f1_score\n",
    "import skfuzzy as fuzz\n",
    "from skfuzzy import control as ctrl\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1912da7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>subject</th>\n",
       "      <th>date</th>\n",
       "      <th>isReal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Colombian president says he left firm listed i...</td>\n",
       "      <td>BOGOTA (Reuters) - Colombian President Juan Ma...</td>\n",
       "      <td>worldnews</td>\n",
       "      <td>November 6, 2017</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Senate Democratic leader Schumer calls for spe...</td>\n",
       "      <td>NEW YORK (Reuters) - U.S. Senate Democratic le...</td>\n",
       "      <td>worldnews</td>\n",
       "      <td>September 25, 2017</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Libyan forces suffer casualties as fighting dr...</td>\n",
       "      <td>BENGHAZI, Libya (Reuters) - Libyan forces figh...</td>\n",
       "      <td>worldnews</td>\n",
       "      <td>December 11, 2017</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Factbox: Trump's policies on immigration, econ...</td>\n",
       "      <td>(Reuters) - Republican presidential candidate ...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>September 27, 2016</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>UK PM May promises to uphold N. Ireland peace ...</td>\n",
       "      <td>LONDON (Reuters) - British Prime Minister Ther...</td>\n",
       "      <td>worldnews</td>\n",
       "      <td>December 8, 2017</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  Colombian president says he left firm listed i...   \n",
       "1  Senate Democratic leader Schumer calls for spe...   \n",
       "2  Libyan forces suffer casualties as fighting dr...   \n",
       "3  Factbox: Trump's policies on immigration, econ...   \n",
       "4  UK PM May promises to uphold N. Ireland peace ...   \n",
       "\n",
       "                                                text       subject  \\\n",
       "0  BOGOTA (Reuters) - Colombian President Juan Ma...     worldnews   \n",
       "1  NEW YORK (Reuters) - U.S. Senate Democratic le...     worldnews   \n",
       "2  BENGHAZI, Libya (Reuters) - Libyan forces figh...     worldnews   \n",
       "3  (Reuters) - Republican presidential candidate ...  politicsNews   \n",
       "4  LONDON (Reuters) - British Prime Minister Ther...     worldnews   \n",
       "\n",
       "                  date  isReal  \n",
       "0    November 6, 2017        1  \n",
       "1  September 25, 2017        1  \n",
       "2   December 11, 2017        1  \n",
       "3  September 27, 2016        1  \n",
       "4    December 8, 2017        1  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the data\n",
    "df_real = pd.read_csv(\"data/real_test_20.csv\") \n",
    "df_fake = pd.read_csv(\"data/fake_test_20.csv\")\n",
    "\n",
    "# Add labels to the datasets\n",
    "df_fake['isReal'] = 0  # add label\n",
    "df_real['isReal'] = 1  # add label\n",
    "\n",
    "# Concatenate real and fake news\n",
    "df = pd.concat([df_real, df_fake]).reset_index(drop = True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a196bd53",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\frank\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>isReal</th>\n",
       "      <th>clean_joined</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>actors quit ferguson play days opening want me...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>body near wreckage russian helicopter svalbard...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>consequences liberal tolerance isis flag hangi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>racists spew hate facebook black people hold a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>sinn fein eyes northern ireland power sharing ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   isReal                                       clean_joined\n",
       "0       0  actors quit ferguson play days opening want me...\n",
       "1       1  body near wreckage russian helicopter svalbard...\n",
       "2       0  consequences liberal tolerance isis flag hangi...\n",
       "3       0  racists spew hate facebook black people hold a...\n",
       "4       1  sinn fein eyes northern ireland power sharing ..."
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Combine title and text together\n",
    "df['combine'] = df['title'] + ' ' + df['text']\n",
    "# Shuffle the dataFrame\n",
    "df = df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# Download stopwords\n",
    "nltk.download(\"stopwords\")\n",
    "\n",
    "# Endlish stopwords\n",
    "stop_words = stopwords.words('english')\n",
    "stop_words[:10]\n",
    "\n",
    "# Remove stopwords and remove words with 2 or less characters\n",
    "def preprocess(text):\n",
    "    result = []\n",
    "    for token in gensim.utils.simple_preprocess(text):\n",
    "        if token not in gensim.parsing.preprocessing.STOPWORDS and len(token) > 3 and token not in stop_words:\n",
    "            result.append(token)\n",
    "            \n",
    "    return result\n",
    "\n",
    "# Apply the function to the dataframe\n",
    "df['clean'] = df['combine'].apply(preprocess)\n",
    "\n",
    "# Join the words into a string\n",
    "df['clean_joined'] = df['clean'].apply(lambda x: \" \".join(x))\n",
    "df = df.drop(columns=['subject', 'title', 'text', 'combine', 'clean', 'date'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a6467ca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace the tokenizer instantiation with BERT tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Convert the dataset to features as the input for Bert model\n",
    "def convert_examples_to_features(texts, tokenizer, max_length=512):\n",
    "    input_ids = []\n",
    "    attention_masks = []\n",
    "\n",
    "    for text in texts:\n",
    "        encoded = tokenizer.encode_plus(\n",
    "            text,\n",
    "            add_special_tokens=True,\n",
    "            max_length=max_length,\n",
    "            padding='max_length',           \n",
    "            return_attention_mask=True,\n",
    "            return_token_type_ids=False,\n",
    "            truncation=True,\n",
    "            return_tensors='pt'              # Output as PyTorch tensors directly\n",
    "        )\n",
    "        input_ids.append(encoded['input_ids'])\n",
    "        attention_masks.append(encoded['attention_mask'])\n",
    "\n",
    "    # Concatenate into big tensors\n",
    "    input_ids = torch.cat(input_ids, dim=0)\n",
    "    attention_masks = torch.cat(attention_masks, dim=0)\n",
    "\n",
    "    return input_ids, attention_masks\n",
    "\n",
    "# Apply on the test data\n",
    "x_test = df['clean_joined']\n",
    "y_test = torch.tensor(df['isReal'].values)  # Labels as PyTorch tensor\n",
    "\n",
    "input_ids, attention_mask = convert_examples_to_features(x_test, tokenizer, max_length=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9b4d92a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement BERT classifier in PyTorch with frozen encoder\n",
    "\n",
    "class BertClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BertClassifier, self).__init__()\n",
    "        \n",
    "        # Load pre-trained BERT\n",
    "        self.bert = BertModel.from_pretrained('bert-base-uncased')\n",
    "        \n",
    "        # Freeze BERT parameters\n",
    "        for param in self.bert.parameters():\n",
    "            param.requires_grad = False\n",
    "        \n",
    "        # Classifier layers\n",
    "        self.pool = nn.AdaptiveAvgPool1d(1)\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        self.fc1 = nn.Linear(self.bert.config.hidden_size, 256)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(256, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        last_hidden_state = outputs.last_hidden_state  # shape: (batch_size, seq_length, hidden_size)\n",
    "\n",
    "        # Global average pooling over the sequence length\n",
    "        x = last_hidden_state.permute(0, 2, 1)  # (batch_size, hidden_size, seq_length)\n",
    "        x = self.pool(x).squeeze(-1)             # (batch_size, hidden_size)\n",
    "\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.sigmoid(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "efc12e7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8979/8979 [01:12<00:00, 123.91it/s]\n"
     ]
    }
   ],
   "source": [
    "# Load the model\n",
    "model = BertClassifier()\n",
    "model.load_state_dict(torch.load(\"bert_pretrain_classifier.pt\"))\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "# Prepare column\n",
    "df['real_prob'] = 0.0\n",
    "\n",
    "# Loop through rows and compute probability\n",
    "for i in tqdm(range(len(df))):\n",
    "    text = df.loc[i, 'clean_joined']\n",
    "\n",
    "    # Tokenize with truncation for BERT input\n",
    "    encoded = tokenizer(\n",
    "        text,\n",
    "        max_length=512,\n",
    "        truncation=True,\n",
    "        padding='max_length',\n",
    "        return_tensors='pt'\n",
    "    )\n",
    "    \n",
    "    input_ids = encoded['input_ids'].to(device)\n",
    "    attention_mask = encoded['attention_mask'].to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = model(input_ids, attention_mask)\n",
    "        prob_real = output.squeeze().item()  # sigmoid output ∈ [0, 1]\n",
    "\n",
    "    df.at[i, 'real_prob'] = prob_real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e3ed4981",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8979/8979 [01:48<00:00, 82.51it/s]\n"
     ]
    }
   ],
   "source": [
    "# Load tokenizer and model\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"GroNLP/mdebertav3-subjectivity-english\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"GroNLP/mdebertav3-subjectivity-english\")\n",
    "\n",
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "# Add columns for subjectivity scores\n",
    "df['subj_score'] = 0.0\n",
    "df['obj_score'] = 0.0\n",
    "\n",
    "# Compute scores for all sentences\n",
    "for i in tqdm(range(len(df))):\n",
    "    text = df.loc[i, 'clean_joined']\n",
    "    \n",
    "    # Tokenize and move to device\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True, max_length=512).to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.logits\n",
    "        probs = torch.softmax(logits, dim=1)[0]\n",
    "        df.at[i, 'subj_score'] = probs[1].item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "003f93b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count tokens and whether they will be truncated\n",
    "df['token_count'] = df['clean_joined'].apply(lambda x: len(tokenizer.encode(x, add_special_tokens=True)))\n",
    "df['was_truncated'] = df['token_count'] > 512"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
